{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from methods.base import BaseConfig\n",
    "from methods.plotting import plot_perm, plot_press, plot_event_list, plot_events_projection\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu' # my gpu is to old for cuda\n",
    "print(device)\n",
    "\n",
    "train_h5_path = 'train.h5'\n",
    "test_h5_path = 'test.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retrieving example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = 142 \n",
    "\n",
    "with h5py.File(train_h5_path, 'a') as f:\n",
    "    ev = f['events'][jj]\n",
    "    pp = f['perm'][jj]\n",
    "    pore = f['pore'][jj]\n",
    "    ev_d = f['ev_dens'][jj]\n",
    "\n",
    "params = BaseConfig()\n",
    "params.load() # loading params from params.yaml\n",
    "\n",
    "print('Permeability map')\n",
    "plot_perm(pp, loc=(10, 10, 10), params=params)\n",
    "\n",
    "print('Pore pressure at the fimal step')\n",
    "plot_press(pore, loc=(10, 10, 10), params=params)\n",
    "\n",
    "print('Events')\n",
    "plot_event_list(ev[0:900], params=params)\n",
    "\n",
    "print('Seismic density at the fimal step')\n",
    "plot_events_projection(ev_d, params=params)\n",
    "\n",
    "print('Pore pressure at the fimal step at source location slice')\n",
    "fig, ax = plt.subplots()\n",
    "ims = ax.imshow(pore[:,:,10]) # pore press at source location slice\n",
    "plt.colorbar(ims, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class EventsToPermDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, h5_path, transforms):\n",
    "        super().__init__()\n",
    "        self.path = h5_path\n",
    "        self.transforms = self.stack_transforms(transforms) # transforms func\n",
    "        with h5py.File(h5_path, 'a') as f:\n",
    "            nmodels = f['events'].shape[0]\n",
    "        self.nmodels = nmodels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.path, 'a') as f:\n",
    "            event = f['events'][idx]\n",
    "            perm = f['perm'][idx]\n",
    "\n",
    "        return self.transforms(event, perm)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nmodels\n",
    "    \n",
    "    def stack_transforms(self, func_list):\n",
    "        def performer(*args):\n",
    "            for f in func_list:\n",
    "                args = f(*args)\n",
    "            return args\n",
    "        return performer\n",
    "    \n",
    "class Normalizer:\n",
    "    ''' returns log10(perm)     '''\n",
    "    def __call__(self, events, perms):\n",
    "        log_perm = torch.log10(perms)\n",
    "        return events, log_perm\n",
    "\n",
    "class ToTensor:\n",
    "    '''Transforms numpy to torch tensors'''\n",
    "    def __call__(self, events, perms):\n",
    "        # perms = torch.tensor(perms, dtype=torch.float)\n",
    "        # events = torch.tensor(events, dtype=torch.float)\n",
    "        perms = torch.Tensor(perms)\n",
    "        events = torch.Tensor(events)\n",
    "        return events, perms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [ToTensor(), Normalizer(),] # data transformations\n",
    "\n",
    "dataset = EventsToPermDataset(h5_path = train_h5_path, transforms=transforms)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset,\n",
    "                      batch_size=10,\n",
    "                      shuffle=False,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some mock model just for testing\n",
    "\n",
    "class MockFc(nn.Module):\n",
    "    '''\n",
    "    Fc layer\n",
    "    '''\n",
    "    def __init__(self, input_shape, target_shape, fc_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "        input_flat_len = torch.zeros(self.input_shape).flatten().shape[0]\n",
    "        target_flat_len = torch.zeros(self.target_shape).flatten().shape[0]\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_flat_len, input_flat_len)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(fc_drop)\n",
    "        self.fc2 = nn.Linear(input_flat_len, target_flat_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0] # batch size\n",
    "        x = x.flatten(0)\n",
    "        x = self.drop(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(bs, *self.target_shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MockEvensToPerm(nn.Module):\n",
    "    '''\n",
    "    Model itself\n",
    "    list of events -> permeability map\n",
    "    '''\n",
    "    def __init__(self, input_shape, target_shape):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.target_shape = target_shape\n",
    "        self.fc = MockFc(self.input_shape, self.target_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.7144, -1.3563,  0.5127,  ..., -0.9286,  4.4130,  2.1863],\n",
       "         [ 1.1066, -0.6971,  2.4352,  ..., -1.5593,  0.5824, -0.8085],\n",
       "         [ 0.4792, -1.2389,  2.6676,  ...,  1.3547,  0.9999, -0.4382],\n",
       "         ...,\n",
       "         [ 1.7099, -1.2539, -1.5202,  ...,  1.2491,  0.3756,  0.0615],\n",
       "         [-3.4966, -1.1421, -4.5903,  ..., -1.9084,  2.0402,  0.8846],\n",
       "         [ 1.5455,  1.3725, -3.6487,  ..., -2.3872,  2.8364, -0.0309]],\n",
       "\n",
       "        [[-1.9420, -3.4582, -1.0865,  ..., -0.8014,  2.1682, -3.1231],\n",
       "         [ 3.9426, -1.0389, -0.1007,  ...,  1.0171, -0.0357,  2.0183],\n",
       "         [-0.5261, -2.4663,  2.3317,  ..., -0.5341,  3.2944, -2.4095],\n",
       "         ...,\n",
       "         [ 4.2126, -3.5338, -1.1002,  ...,  2.1183,  0.7094, -0.7294],\n",
       "         [ 1.6446,  1.4953,  0.0085,  ...,  1.2181,  0.9027,  2.9585],\n",
       "         [-0.0262, -0.4036, -0.8714,  ..., -1.4647,  0.0601,  1.5520]],\n",
       "\n",
       "        [[ 2.4198, -0.2293,  0.3937,  ..., -3.8375, -0.5768, -1.3801],\n",
       "         [-0.8696,  1.8189, -3.2175,  ..., -0.5764,  2.2763,  0.4812],\n",
       "         [ 0.9253, -0.4189, -1.0949,  ...,  0.5661,  2.2007,  2.6789],\n",
       "         ...,\n",
       "         [-0.4249,  0.6222,  1.0849,  ..., -1.9643, -0.5671, -2.0720],\n",
       "         [ 0.8001,  0.8621,  0.0946,  ..., -1.3384, -1.1425,  0.6151],\n",
       "         [-1.0745, -3.0571,  1.4351,  ..., -1.6379, -4.1255, -1.1148]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.7134, -1.1054,  0.4001,  ...,  1.5139,  2.9884,  0.9030],\n",
       "         [ 0.2545, -1.9768, -0.5308,  ...,  1.3337, -0.2641, -2.2016],\n",
       "         [ 0.8614,  0.7950,  2.9786,  ...,  0.4737,  2.8886,  0.3862],\n",
       "         ...,\n",
       "         [ 0.3408, -0.3442,  0.4424,  ...,  3.8016,  0.8495,  0.4025],\n",
       "         [-1.5365,  1.3627, -1.3467,  ...,  6.2072, -3.4885, -1.0917],\n",
       "         [-0.2053,  0.1218, -2.2740,  ...,  2.0976, -3.2966, -0.2095]],\n",
       "\n",
       "        [[-2.2284, -4.6591, -0.3279,  ...,  0.8970,  1.4629,  1.1575],\n",
       "         [ 2.0918, -0.5586,  0.4286,  ..., -1.0454,  1.4010,  5.7745],\n",
       "         [-0.1450,  1.5220, -0.7152,  ..., -1.3544,  0.6083,  2.1484],\n",
       "         ...,\n",
       "         [ 0.6204, -1.9588, -3.2871,  ..., -1.0846,  1.0507,  1.1804],\n",
       "         [-2.5759, -2.5850, -0.2925,  ..., -1.5995,  3.2265,  0.2148],\n",
       "         [ 3.5539, -1.1165, -3.8834,  ..., -0.4219,  0.7835,  0.5650]],\n",
       "\n",
       "        [[ 0.9947, -0.2884,  0.4213,  ..., -1.9615, -6.8099,  0.6305],\n",
       "         [-0.4081, -0.6152, -2.8183,  ..., -0.1566,  0.8387, -0.2052],\n",
       "         [-0.3661, -3.0132, -1.9258,  ..., -0.2071,  3.3303, -0.6445],\n",
       "         ...,\n",
       "         [-4.3852,  3.2211, -0.1653,  ..., -1.7691,  0.4700,  3.0685],\n",
       "         [ 4.4112,  3.2210,  2.6918,  ...,  0.4307, -0.1837,  1.3688],\n",
       "         [-0.7803,  1.3854, -1.9640,  ..., -0.0471, -0.0090,  0.6976]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = dataset[0]\n",
    "\n",
    "model = MockEvensToPerm(X.shape, y.shape)\n",
    "                        \n",
    "y_hat = model(X.unsqueeze(0)).squeeze(0)\n",
    "y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1100, 5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.unsqueeze(0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
